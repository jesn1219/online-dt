{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.3787e+00],\n",
      "        [-1.6671e+02],\n",
      "        [-1.0803e+04],\n",
      "        [-4.4501e+04],\n",
      "        [-2.0007e+04],\n",
      "        [-8.3776e+04],\n",
      "        [-4.2887e+03],\n",
      "        [-3.3194e+01],\n",
      "        [-3.4077e+03],\n",
      "        [-3.8216e+04],\n",
      "        [-4.2032e+03],\n",
      "        [-1.5372e+05],\n",
      "        [-1.8730e+04],\n",
      "        [-9.0873e+00],\n",
      "        [-4.5264e+04],\n",
      "        [-5.1000e+04],\n",
      "        [-5.8880e+03],\n",
      "        [-6.3658e+04],\n",
      "        [-6.3684e+03],\n",
      "        [-7.7166e+03],\n",
      "        [-1.5558e+04],\n",
      "        [-3.7459e+02],\n",
      "        [-1.0210e+02],\n",
      "        [-2.9861e+03],\n",
      "        [-8.5973e+03],\n",
      "        [-7.7735e+03],\n",
      "        [-3.4323e+03],\n",
      "        [-1.1128e+03],\n",
      "        [-7.8199e+03],\n",
      "        [-2.3401e+04],\n",
      "        [-1.7543e+04],\n",
      "        [-1.9214e+02],\n",
      "        [-2.3474e+03],\n",
      "        [-1.4360e+05],\n",
      "        [-6.5525e+02],\n",
      "        [-2.5245e+01],\n",
      "        [-1.0918e+02],\n",
      "        [-3.3024e+03],\n",
      "        [-2.9143e+03],\n",
      "        [-2.2422e+02],\n",
      "        [-7.7976e+03],\n",
      "        [-1.6789e+01],\n",
      "        [-3.4572e+04],\n",
      "        [-1.5653e+03],\n",
      "        [-8.2813e+04],\n",
      "        [-9.8826e+03],\n",
      "        [-4.2639e+04],\n",
      "        [-6.8035e+04],\n",
      "        [-6.7775e+03],\n",
      "        [-1.9965e+03],\n",
      "        [-4.0758e+03],\n",
      "        [-2.2265e+04],\n",
      "        [-1.4776e+03],\n",
      "        [-7.6496e+04],\n",
      "        [-1.0700e+04],\n",
      "        [-1.1890e+03],\n",
      "        [-4.4920e+04],\n",
      "        [-4.8000e+04],\n",
      "        [-5.9046e+02],\n",
      "        [-6.0443e+03],\n",
      "        [-2.7104e+02],\n",
      "        [-4.7671e+00],\n",
      "        [-1.1144e+03],\n",
      "        [-5.6096e+04],\n",
      "        [-8.4682e+03],\n",
      "        [-3.7533e+04],\n",
      "        [-1.5440e+00],\n",
      "        [-5.6160e+03],\n",
      "        [-9.7222e+01],\n",
      "        [-2.9281e+03],\n",
      "        [-3.9663e+02],\n",
      "        [-1.7645e+03],\n",
      "        [-1.9845e+03],\n",
      "        [-4.9750e+03],\n",
      "        [-6.6623e+02],\n",
      "        [-1.2222e+04],\n",
      "        [-9.6393e+03],\n",
      "        [-4.6007e+03],\n",
      "        [-9.4732e+03],\n",
      "        [-5.7287e+02],\n",
      "        [-1.0311e+04],\n",
      "        [-7.9045e+04],\n",
      "        [-2.2921e+04],\n",
      "        [-1.2825e+02],\n",
      "        [-2.3720e+04],\n",
      "        [-3.3493e+03],\n",
      "        [-3.7454e+04],\n",
      "        [-6.5894e+03],\n",
      "        [-1.2602e+04],\n",
      "        [-1.3926e+03],\n",
      "        [-4.9988e+04],\n",
      "        [-1.5451e+02],\n",
      "        [-2.5979e+04],\n",
      "        [-7.1899e+04],\n",
      "        [-4.6933e+03],\n",
      "        [-4.4455e+03],\n",
      "        [-6.4267e+04],\n",
      "        [-2.4498e+03],\n",
      "        [-6.2109e+04],\n",
      "        [-1.0341e+03],\n",
      "        [-9.8319e+04],\n",
      "        [-3.2781e+04],\n",
      "        [-6.2730e+03],\n",
      "        [-7.2203e+03],\n",
      "        [-3.7633e+02],\n",
      "        [-2.9557e+03],\n",
      "        [-5.3407e+02],\n",
      "        [-5.4592e+04],\n",
      "        [-1.2895e+04],\n",
      "        [-2.4300e+03],\n",
      "        [-1.0119e+03],\n",
      "        [-2.7282e+04],\n",
      "        [-3.8170e+03],\n",
      "        [-3.7548e+04],\n",
      "        [-1.6737e+03],\n",
      "        [-2.0783e+02],\n",
      "        [-5.4353e+03],\n",
      "        [-1.8192e+02],\n",
      "        [-1.2792e+00],\n",
      "        [-3.0305e+04],\n",
      "        [-3.0590e+03],\n",
      "        [-1.5908e+04],\n",
      "        [-5.4907e+02],\n",
      "        [-1.7257e+04],\n",
      "        [-1.6309e+04],\n",
      "        [-5.6303e+03],\n",
      "        [-9.2518e+03],\n",
      "        [-4.9883e+03],\n",
      "        [-1.9196e+04],\n",
      "        [-2.2879e+04],\n",
      "        [-4.2873e+04],\n",
      "        [-3.1087e+04],\n",
      "        [-1.6548e+05],\n",
      "        [-2.3950e+02],\n",
      "        [-1.1206e+05],\n",
      "        [-4.2263e+03],\n",
      "        [-1.7440e+03],\n",
      "        [-2.8957e+01],\n",
      "        [-2.5722e+04],\n",
      "        [-7.7054e+04],\n",
      "        [-1.6155e+02],\n",
      "        [-1.6280e+04],\n",
      "        [-1.0272e+01],\n",
      "        [-1.9083e+01],\n",
      "        [-1.4256e+02],\n",
      "        [-5.0582e+04],\n",
      "        [-3.5920e+02],\n",
      "        [-8.7231e+03],\n",
      "        [-3.1567e+01],\n",
      "        [-2.6519e+04],\n",
      "        [-1.7151e+03],\n",
      "        [-2.9517e+03],\n",
      "        [-9.0155e+04],\n",
      "        [-7.6693e+03],\n",
      "        [-7.3740e+04],\n",
      "        [-6.3255e+03],\n",
      "        [-1.1300e+04],\n",
      "        [-1.0897e+04],\n",
      "        [-9.5678e+01],\n",
      "        [-3.5468e+04],\n",
      "        [-2.1426e+03],\n",
      "        [-3.4423e+03],\n",
      "        [-1.5301e+04],\n",
      "        [-7.1783e+03],\n",
      "        [-2.0094e+04],\n",
      "        [-1.7188e+05],\n",
      "        [-2.6964e+04],\n",
      "        [-1.5364e+04],\n",
      "        [-9.1521e+04],\n",
      "        [-5.1489e+04],\n",
      "        [-4.9856e+04],\n",
      "        [-1.8943e+04],\n",
      "        [-7.0330e+04],\n",
      "        [-2.7633e+02],\n",
      "        [-3.7521e+03],\n",
      "        [-7.4980e+04],\n",
      "        [-8.8193e+04],\n",
      "        [-4.5488e+04],\n",
      "        [-1.3925e+04],\n",
      "        [-2.2544e+04],\n",
      "        [-4.0256e+03],\n",
      "        [-7.2451e+01],\n",
      "        [-8.0914e+03],\n",
      "        [-1.4103e+04],\n",
      "        [-1.5161e+04],\n",
      "        [-3.5363e+02],\n",
      "        [-3.3025e+04],\n",
      "        [-9.2484e+03],\n",
      "        [-5.2711e+03],\n",
      "        [-5.3545e+04],\n",
      "        [-1.4526e+03],\n",
      "        [-4.7360e+03],\n",
      "        [-1.1446e+04],\n",
      "        [-3.7193e+04],\n",
      "        [-4.4817e+02],\n",
      "        [-4.9202e+04],\n",
      "        [-5.2413e+04],\n",
      "        [-4.6940e+04],\n",
      "        [-7.8383e+04],\n",
      "        [-5.6278e+04],\n",
      "        [-7.6489e+01],\n",
      "        [-1.8196e+01],\n",
      "        [-2.5124e+04],\n",
      "        [-9.9820e+03],\n",
      "        [-4.6651e+04],\n",
      "        [-6.8291e+04],\n",
      "        [-7.7386e+04],\n",
      "        [-2.8868e+04],\n",
      "        [-3.4709e+01],\n",
      "        [-2.9567e+03],\n",
      "        [-6.5342e+04],\n",
      "        [-6.1067e+04],\n",
      "        [-3.8562e+04],\n",
      "        [-6.9041e+04],\n",
      "        [-1.0133e+04],\n",
      "        [-2.7841e+00],\n",
      "        [-5.5299e+04],\n",
      "        [-2.2690e+03],\n",
      "        [-2.9315e+02],\n",
      "        [-2.0786e+04],\n",
      "        [-9.6310e+02],\n",
      "        [-8.9679e+04],\n",
      "        [-3.6453e+03],\n",
      "        [-1.7845e+04],\n",
      "        [-1.3323e+04],\n",
      "        [-1.9197e+04],\n",
      "        [-3.9813e+02],\n",
      "        [-8.7948e+02],\n",
      "        [-2.8726e+03],\n",
      "        [-4.1650e+02],\n",
      "        [-8.8352e+02],\n",
      "        [-1.8912e+04],\n",
      "        [-7.0881e+04],\n",
      "        [-2.1776e+04],\n",
      "        [-1.1087e+03],\n",
      "        [ 6.7291e-01],\n",
      "        [-6.0606e+04],\n",
      "        [-4.1446e+04],\n",
      "        [-1.6901e+04],\n",
      "        [-3.7733e+02],\n",
      "        [-4.6466e+04],\n",
      "        [-8.6828e+04],\n",
      "        [-2.4427e+04],\n",
      "        [-1.0866e+05],\n",
      "        [-1.0233e+01],\n",
      "        [-4.9150e+04],\n",
      "        [-7.8645e+02],\n",
      "        [-2.8991e+03],\n",
      "        [-1.7025e+04],\n",
      "        [-5.2418e+02],\n",
      "        [-3.0243e+03],\n",
      "        [-1.4073e+04],\n",
      "        [-2.9410e+04],\n",
      "        [-3.2690e+02],\n",
      "        [-2.3910e+04],\n",
      "        [-5.6220e+01]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "\n",
    "from decision_transformer.models.model import TrajectoryModel\n",
    "from decision_transformer.models.trajectory_gpt2 import GPT2Model\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as pyd\n",
    "\n",
    "\n",
    "class TanhTransform(pyd.transforms.Transform):\n",
    "    domain = pyd.constraints.real\n",
    "    codomain = pyd.constraints.interval(-1.0, 1.0)\n",
    "    bijective = True\n",
    "    sign = +1\n",
    "\n",
    "    def __init__(self, cache_size=1):\n",
    "        super().__init__(cache_size=cache_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def atanh(x):\n",
    "        return 0.5 * (x.log1p() - (-x).log1p())\n",
    "\n",
    "        # atanh 함수는 [-1, 1] 범위 밖의 값에 대해 정의되지 않으므로, 입력을 이 범위 내로 제한\n",
    "        eps = 1e-6  # 소수값을 추가하여 -1과 1에서의 수치적 불안정성을 방지\n",
    "        return 0.5 * (x.clamp(-1 + eps, 1 - eps).log1p() - (-x).clamp(-1 + eps, 1 - eps).log1p())\n",
    "\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, TanhTransform)\n",
    "\n",
    "    def _call(self, x):\n",
    "        return x.tanh()\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        # We do not clamp to the boundary here as it may degrade the performance of certain algorithms.\n",
    "        # one should use `cache_size=1` instead\n",
    "        return self.atanh(y)\n",
    "\n",
    "    def log_abs_det_jacobian(self, x, y):\n",
    "        # We use a formula that is more numerically stable, see details in the following link\n",
    "        # https://github.com/tensorflow/probability/commit/ef6bb176e0ebd1cf6e25c6b5cecdd2428c22963f#diff-e120f70e92e6741bca649f04fcd907b7\n",
    "        return 2.0 * (math.log(2.0) - x - F.softplus(-2.0 * x))\n",
    "\n",
    "\n",
    "class SquashedNormal(pyd.transformed_distribution.TransformedDistribution):\n",
    "    \"\"\"\n",
    "    Squashed Normal Distribution(s)\n",
    "\n",
    "    If loc/std is of size (batch_size, sequence length, d),\n",
    "    this returns batch_size * sequence length * d\n",
    "    independent squashed univariate normal distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loc, std):\n",
    "        self.loc = loc\n",
    "        self.std = std\n",
    "        self.base_dist = pyd.Normal(loc, std)\n",
    "\n",
    "        transforms = [TanhTransform()]\n",
    "\n",
    "        super().__init__(self.base_dist, transforms)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        mu = self.loc\n",
    "        for tr in self.transforms:\n",
    "            mu = tr(mu)\n",
    "        return mu\n",
    "\n",
    "    def entropy(self, N=1):\n",
    "        # sample from the distribution and then compute\n",
    "        # the empirical entropy:\n",
    "        x = self.rsample((N,))\n",
    "        log_p = self.log_prob(x)\n",
    "\n",
    "        # log_p: (batch_size, context_len, action_dim),\n",
    "        return -log_p.mean(axis=0).sum(axis=2)\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        # log_prob(x): (batch_size, context_len, action_dim)\n",
    "        # sum up along the action dimensions\n",
    "        # Return tensor shape: (batch_size, context_len)\n",
    "        \n",
    "        x = self.transforms[0](x)        \n",
    "        return self.log_prob(x).sum(axis=2)\n",
    "\n",
    "        # transform x to the original distribution\n",
    "        for tr in reversed(self.transforms):\n",
    "            x = tr.inv(x)\n",
    "        return self.base_dist.log_prob(x).sum(axis=2)\n",
    "        return self.log_prob(x).sum(axis=2)\n",
    "\n",
    "\n",
    "\n",
    "class DiagGaussianActor(nn.Module):\n",
    "    \"\"\"torch.distributions implementation of an diagonal Gaussian policy.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, act_dim, log_std_bounds=[-5.0, 2.0], transform_type = 'tanh', value_range = [-1.0, 1.0]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mu = torch.nn.Linear(hidden_dim, act_dim)\n",
    "        self.log_std = torch.nn.Linear(hidden_dim, act_dim)\n",
    "        self.log_std_bounds = log_std_bounds\n",
    "        self.transform_type = transform_type\n",
    "        self.value_range = value_range\n",
    "        def weight_init(m):\n",
    "            \"\"\"Custom weight init for Conv2D and Linear layers.\"\"\"\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight.data)\n",
    "                if hasattr(m.bias, \"data\"):\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        mu, log_std = self.mu(obs), self.log_std(obs)\n",
    "        log_std = torch.tanh(log_std)\n",
    "        # log_std is the output of tanh so it will be between [-1, 1]\n",
    "        # map it to be between [log_std_min, log_std_max]\n",
    "        log_std_min, log_std_max = self.log_std_bounds\n",
    "        log_std = log_std_min + 0.5 * (log_std_max - log_std_min) * (log_std + 1.0)\n",
    "        std = log_std.exp()\n",
    "        return SquashedNormal(mu, std)\n",
    "\n",
    "predict_state = DiagGaussianActor(512, 4, transform_type='tanh')\n",
    "obs = torch.randn(256,1, 512)\n",
    "predict_s = predict_state(obs)  \n",
    "print(predict_s.log_likelihood(torch.ones(1, 4)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "tensor([[1.1000, 1.1000, 1.1000, 1.1000]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The value argument must be within the support",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 111\u001b[0m, in \u001b[0;36mSquashedNormal.log_likelihood\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_prob(x)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/torch/distributions/transformed_distribution.py:138\u001b[0m, in \u001b[0;36mTransformedDistribution.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03mScores the sample by inverting the transform(s) and computing the score\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03musing the score of the base distribution and the log abs det jacobian.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m event_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_shape)\n\u001b[1;32m    140\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m/env/lib/python3.8/site-packages/torch/distributions/distribution.py:277\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m support \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m support\u001b[38;5;241m.\u001b[39mcheck(value)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe value argument must be within the support\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The value argument must be within the support"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
