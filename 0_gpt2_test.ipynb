{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "\n",
    "from decision_transformer.models.model import TrajectoryModel\n",
    "from decision_transformer.models.trajectory_gpt2 import GPT2Model\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as pyd\n",
    "\n",
    "\n",
    "class TanhTransform(pyd.transforms.Transform):\n",
    "    domain = pyd.constraints.real\n",
    "    codomain = pyd.constraints.interval(-1.0, 1.0)\n",
    "    bijective = True\n",
    "    sign = +1\n",
    "\n",
    "    def __init__(self, cache_size=1):\n",
    "        super().__init__(cache_size=cache_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def atanh(x):\n",
    "        return 0.5 * (x.log1p() - (-x).log1p())\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, TanhTransform)\n",
    "\n",
    "    def _call(self, x):\n",
    "        return x.tanh()\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        # We do not clamp to the boundary here as it may degrade the performance of certain algorithms.\n",
    "        # one should use `cache_size=1` instead\n",
    "        return self.atanh(y)\n",
    "\n",
    "    def log_abs_det_jacobian(self, x, y):\n",
    "        # We use a formula that is more numerically stable, see details in the following link\n",
    "        # https://github.com/tensorflow/probability/commit/ef6bb176e0ebd1cf6e25c6b5cecdd2428c22963f#diff-e120f70e92e6741bca649f04fcd907b7\n",
    "        return 2.0 * (math.log(2.0) - x - F.softplus(-2.0 * x))\n",
    "\n",
    "\n",
    "\n",
    "class SquashedNormal(pyd.transformed_distribution.TransformedDistribution):\n",
    "    \"\"\"\n",
    "    Squashed Normal Distribution(s)\n",
    "\n",
    "    If loc/std is of size (batch_size, sequence length, d),\n",
    "    this returns batch_size * sequence length * d\n",
    "    independent squashed univariate normal distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, loc, std):\n",
    "        self.loc = loc\n",
    "        self.std = std\n",
    "        self.base_dist = pyd.Normal(loc, std)\n",
    "\n",
    " \n",
    "        transforms = [TanhTransform()]\n",
    "\n",
    "        super().__init__(self.base_dist, transforms)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        mu = self.loc\n",
    "        for tr in self.transforms:\n",
    "            mu = tr(mu)\n",
    "        return mu\n",
    "\n",
    "    def entropy(self, N=1):\n",
    "        # sample from the distribution and then compute\n",
    "        # the empirical entropy:\n",
    "        x = self.rsample((N,))\n",
    "        log_p = self.log_prob(x)\n",
    "\n",
    "        # log_p: (batch_size, context_len, action_dim),\n",
    "        return -log_p.mean(axis=0).sum(axis=2)\n",
    "\n",
    "    def log_likelihood(self, x):\n",
    "        # log_prob(x): (batch_size, context_len, action_dim)\n",
    "        # sum up along the action dimensions\n",
    "        # Return tensor shape: (batch_size, context_len)\n",
    "\n",
    "        x = self.transforms[0](x)        \n",
    "        return self.log_prob(x).sum(axis=2)\n",
    "\n",
    "        # jesnk : this is the log likelihood of the state # jesnk: mark1\n",
    "        for tr in reversed(self.transforms):\n",
    "            x = tr.inv(x)\n",
    "        return self.base_dist.log_prob(x).sum(axis=2)\n",
    "\n",
    "\n",
    "\n",
    "class DiagGaussianActor(nn.Module):\n",
    "    \"\"\"torch.distributions implementation of an diagonal Gaussian policy.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, act_dim, log_std_bounds=[-5.0, 2.0]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mu = torch.nn.Linear(hidden_dim, act_dim)\n",
    "        self.log_std = torch.nn.Linear(hidden_dim, act_dim)\n",
    "        self.log_std_bounds = log_std_bounds\n",
    "        def weight_init(m):\n",
    "            \"\"\"Custom weight init for Conv2D and Linear layers.\"\"\"\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight.data)\n",
    "                if hasattr(m.bias, \"data\"):\n",
    "                    m.bias.data.fill_(0.0)\n",
    "\n",
    "        self.apply(weight_init)\n",
    "\n",
    "    def forward(self, obs):\n",
    "        mu, log_std = self.mu(obs), self.log_std(obs)\n",
    "        print(mu.shape, log_std.shape)\n",
    "        log_std = torch.tanh(log_std)\n",
    "        # log_std is the output of tanh so it will be between [-1, 1]\n",
    "        # map it to be between [log_std_min, log_std_max]\n",
    "        log_std_min, log_std_max = self.log_std_bounds\n",
    "        log_std = log_std_min + 0.5 * (log_std_max - log_std_min) * (log_std + 1.0)\n",
    "        std = log_std.exp()\n",
    "        return SquashedNormal(mu, std)\n",
    "\n",
    "\n",
    "from decision_transformer.models.model import TrajectoryModel01\n",
    "class DecisionTransformer02(TrajectoryModel01):\n",
    "\n",
    "    \"\"\"\n",
    "    This model uses GPT to model (Return_1, state_1, action_1, Return_2, state_2, ...)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    jesnk: this model uses gpt to model (state_1, state_2, ..., state_n)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim,\n",
    "        hidden_size,\n",
    "        state_range,\n",
    "        ordering=0,\n",
    "        act_dim = None,\n",
    "        max_length=None,\n",
    "        eval_context_length=None,\n",
    "        max_ep_len=4096,\n",
    "        state_tanh=True,\n",
    "        stochastic_policy=False,\n",
    "        init_temperature=0.1,\n",
    "        target_entropy=None,\n",
    "        state_mean=None, #jesnk\n",
    "        state_std=None, #jesnk\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(state_dim, max_length=max_length)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        config = transformers.GPT2Config(\n",
    "            vocab_size=1,  # doesn't matter -- we don't use the vocab\n",
    "            n_embd=hidden_size,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # note: the only difference between this GPT2Model and the default Huggingface version\n",
    "        # is that the positional embeddings are removed (since we'll add those ourselves)\n",
    "        self.transformer = GPT2Model(config)\n",
    "\n",
    "        self.embed_timestep = nn.Embedding(max_ep_len, hidden_size)\n",
    "        if ordering:\n",
    "            self.embed_ordering = nn.Embedding(max_ep_len, hidden_size)\n",
    "        self.embed_state = torch.nn.Linear(self.state_dim, hidden_size)\n",
    "        \n",
    "        self.embed_ln = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        if stochastic_policy:\n",
    "            self.predict_state = DiagGaussianActor(hidden_size, self.state_dim)\n",
    "        else:\n",
    "            self.predict_state = nn.Sequential(\n",
    "                *(\n",
    "                    [nn.Linear(hidden_size, self.state_dim)]\n",
    "                    + ([nn.Tanh()] if state_tanh else [])\n",
    "                )\n",
    "            )\n",
    "        self.stochastic_policy = stochastic_policy\n",
    "        self.eval_context_length = eval_context_length\n",
    "        self.ordering = ordering\n",
    "        self.state_range = state_range\n",
    "        #self.state_mean = state_mean # jesnk\n",
    "        #self.state_std = state_std # jesnk\n",
    "        #print(f'jesnk: debug: DT01: state_mean:{self.state_mean}, state_std:{self.state_std}')\n",
    "\n",
    "\n",
    "        if stochastic_policy:\n",
    "            self.log_temperature = torch.tensor(np.log(init_temperature))\n",
    "            self.log_temperature.requires_grad = True\n",
    "            self.target_entropy = target_entropy\n",
    "\n",
    "    def temperature(self):\n",
    "        if self.stochastic_policy:\n",
    "            return self.log_temperature.exp()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        states,\n",
    "        timesteps=None,\n",
    "        ordering=None,\n",
    "        padding_mask=None,\n",
    "    ):\n",
    "\n",
    "        batch_size, seq_length = states.shape[0], states.shape[1] # 512, seq_legnth, \n",
    "\n",
    "        if padding_mask is None:\n",
    "            # attention mask for GPT: 1 if can be attended to, 0 if not\n",
    "            padding_mask = torch.ones((batch_size, seq_length), dtype=torch.long)\n",
    "        if timesteps is None :\n",
    "            timesteps = torch.arange(seq_length, device=states.device).repeat(batch_size, 1)\n",
    "\n",
    "        # embed each modality with a different head\n",
    "        state_embeddings = self.embed_state(states)\n",
    "\n",
    "        if self.ordering:\n",
    "            order_embeddings = self.embed_ordering(timesteps)\n",
    "        else:\n",
    "            order_embeddings = 0.0\n",
    "\n",
    "        state_embeddings = state_embeddings + order_embeddings\n",
    "\n",
    "        # this makes the sequence look like (R_1, s_1, a_1, R_2, s_2, a_2, ...)\n",
    "        # which works nice in an autoregressive sense since states predict actions\n",
    "        # state_embeddings.shape: batch, seq_length, hidden_size\n",
    "        stacked_inputs = (\n",
    "            #torch.stack((state_embeddings), dim=1)\n",
    "            state_embeddings # batch, seq_length, hidden_size\n",
    "            #.permute(0, 2, 1, 3) # batch, seq_length, 1, hidden_size\n",
    "            .reshape(batch_size, 1 * seq_length, self.hidden_size)\n",
    "        )\n",
    "        # stacked_inputs.shape: batch, 1*seq_length, hidden_size\n",
    "        stacked_inputs = self.embed_ln(stacked_inputs)\n",
    "\n",
    "        # to make the attention mask fit the stacked inputs, have to stack it as well\n",
    "        stacked_padding_mask = (\n",
    "            #torch.stack((padding_mask, padding_mask, padding_mask), dim=1)\n",
    "            padding_mask\n",
    "            #.permute(0, 2, 1)\n",
    "            .reshape(batch_size, 1 * seq_length)\n",
    "        )\n",
    "\n",
    "        # we feed in the input embeddings (not word indices as in NLP) to the model\n",
    "        transformer_outputs = self.transformer(\n",
    "            inputs_embeds=stacked_inputs,\n",
    "            attention_mask=stacked_padding_mask,\n",
    "        )\n",
    "        x = transformer_outputs[\"last_hidden_state\"]\n",
    "\n",
    "        # reshape x so that the second dimension corresponds to the original\n",
    "        # returns (0), states (1), or actions (2); i.e. x[:,1,t] is the token for s_t\n",
    "        x = x.reshape(batch_size, seq_length, 1, self.hidden_size).permute(0, 2, 1, 3)\n",
    "        # after reshape : batch, 1, seq_length, hidden_size\n",
    "        # get predictions\n",
    "        # predict next state given state and action\n",
    "\n",
    "        #state_preds = self.predict_state(x[:, 0]) # jesnk: DT1 setting\n",
    "        states_pred = self.predict_state(x[:,0]) # jesnk: must check the index of [:, 0] is correct\n",
    "\n",
    "        # state_preds.shape: batch, seq_length, state_dim\n",
    "        return states_pred\n",
    "\n",
    "    def get_predictions(\n",
    "        self, states, timesteps, num_envs=1, **kwargs\n",
    "    ):\n",
    "        # we don't care about the past rewards in this model\n",
    "        # tensor shape: batch_size, seq_length, variable_dim\n",
    "        states = states.reshape(num_envs, -1, self.state_dim)\n",
    "\n",
    "        # tensor shape: batch_size, seq_length\n",
    "        timesteps = timesteps.reshape(num_envs, -1)\n",
    "\n",
    "        # max_length is the DT context length (should be input length of the subsequence)\n",
    "        # eval_context_length is the how long you want to use the history for your prediction\n",
    "        if self.max_length is not None:\n",
    "            states = states[:, -self.eval_context_length :]\n",
    "            timesteps = timesteps[:, -self.eval_context_length :]\n",
    "\n",
    "            ordering = torch.tile(\n",
    "                torch.arange(timesteps.shape[1], device=states.device),\n",
    "                (num_envs, 1),\n",
    "            )\n",
    "            # pad all tokens to sequence length\n",
    "            padding_mask = torch.cat(\n",
    "                [\n",
    "                    torch.zeros(self.max_length - states.shape[1]),\n",
    "                    torch.ones(states.shape[1]),\n",
    "                ]\n",
    "            )\n",
    "            padding_mask = padding_mask.to(\n",
    "                dtype=torch.long, device=states.device\n",
    "            ).reshape(1, -1)\n",
    "            padding_mask = padding_mask.repeat((num_envs, 1))\n",
    "\n",
    "            states = torch.cat(\n",
    "                [\n",
    "                    torch.zeros(\n",
    "                        (\n",
    "                            states.shape[0],\n",
    "                            self.max_length - states.shape[1],\n",
    "                            self.state_dim,\n",
    "                        ),\n",
    "                        device=states.device,\n",
    "                    ),\n",
    "                    states,\n",
    "                ],\n",
    "                dim=1,\n",
    "            ).to(dtype=torch.float32)\n",
    "            \n",
    "            timesteps = torch.cat(\n",
    "                [\n",
    "                    torch.zeros(\n",
    "                        (timesteps.shape[0], self.max_length - timesteps.shape[1]),\n",
    "                        device=timesteps.device,\n",
    "                    ),\n",
    "                    timesteps,\n",
    "                ],\n",
    "                dim=1,\n",
    "            ).to(dtype=torch.long)\n",
    "\n",
    "            ordering = torch.cat(\n",
    "                [\n",
    "                    torch.zeros(\n",
    "                        (ordering.shape[0], self.max_length - ordering.shape[1]),\n",
    "                        device=ordering.device,\n",
    "                    ),\n",
    "                    ordering,\n",
    "                ],\n",
    "                dim=1,\n",
    "            ).to(dtype=torch.long)\n",
    "        else:\n",
    "            padding_mask = None\n",
    "\n",
    "        state_preds = self.forward(\n",
    "            states,\n",
    "            timesteps,\n",
    "            ordering,\n",
    "            padding_mask=padding_mask,\n",
    "            **kwargs\n",
    "        )\n",
    "        if self.stochastic_policy:\n",
    "            return state_preds\n",
    "        else:\n",
    "            return (\n",
    "                self.clamp_state(state_preds[:, -1])\n",
    "            )\n",
    "\n",
    "    def clamp_state(self, state):\n",
    "        return state.clamp(*self.state_range)\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        self.eval()\n",
    "        return self\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시퀀스 데이터 예시: [[0.27728443 0.28728443 0.29728443 0.30728443 0.31728443]\n",
      " [0.19605102 0.20605102 0.21605102 0.22605102 0.23605102]\n",
      " [0.89598362 0.90598362 0.91598362 0.92598362 0.93598362]\n",
      " [0.66323702 0.67323702 0.68323702 0.69323702 0.70323702]\n",
      " [0.3010093  0.3110093  0.3210093  0.3310093  0.3410093 ]]\n",
      "데이터셋 크기: 500000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 시퀀스 데이터 생성 함수\n",
    "def create_sequences(seq_length=5, num_sequences=1000, start=-1.0, end=1.0, step=0.01):\n",
    "    sequences = []\n",
    "    while len(sequences) < num_sequences:\n",
    "        start_val = random.uniform(start, end - seq_length * step)\n",
    "        sequence = [start_val + i * step for i in range(seq_length)]\n",
    "        if all(-1 <= x <= 1 for x in sequence):  # 시퀀스 내 모든 값이 -1과 1 사이인지 확인\n",
    "            sequences.append(sequence)\n",
    "    return np.array(sequences)\n",
    "\n",
    "# 데이터셋 클래스\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        #self.sequences = sequences\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.float).to(device)\n",
    "        \n",
    "        # \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        input_seq = sequence[:-1]  # 입력 시퀀스 (마지막 토큰 제외)\n",
    "        target_seq = sequence[1:]  # 타겟 시퀀스 (첫 번째 토큰 제외)\n",
    "        return input_seq.clone().detach(), target_seq.clone().detach()\n",
    "\n",
    "\n",
    "seq_data_length = 5  # 시퀀스 데이터 길이\n",
    "seq_length = seq_data_length -1  # 입력 시퀀스 길이\n",
    "num_sequences = 500000  # 시퀀스 데이터 개수\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "#embed_dim = 512 # 임베딩 차원\n",
    "#num_heads = 4   # 어텐션 헤드 수\n",
    "#num_layers = 6  # 트랜스포머 블록 수\n",
    "#batch_size = 1\n",
    "#lr = 1e-6\n",
    "\n",
    "total_epoch = 1000\n",
    "\n",
    "# 시퀀스 데이터 생성 및 데이터셋 객체 생성\n",
    "sequences = create_sequences(seq_length=seq_data_length, num_sequences=num_sequences)\n",
    "dataset = SequenceDataset(sequences)\n",
    "\n",
    "# 데이터셋 예시 출력\n",
    "print(\"시퀀스 데이터 예시:\", sequences[:5])\n",
    "print(\"데이터셋 크기:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "variant = {}\n",
    "variant[\"state_dim\"] = 1\n",
    "variant[\"state_range\"] = np.array([-1.0, 1.0])\n",
    "variant[\"K\"] = 5\n",
    "MAX_EPISODE_LEN = 1000\n",
    "variant[\"embed_dim\"] = 512\n",
    "variant[\"n_layer\"] = 4\n",
    "variant[\"n_head\"] = 4\n",
    "variant[\"activation_function\"] = \"gelu\"\n",
    "variant[\"dropout\"] = 0.1\n",
    "variant[\"ordering\"] = 0\n",
    "variant[\"init_temperature\"] = 0.1\n",
    "variant[\"target_entropy\"] = -variant[\"state_dim\"]\n",
    "variant[\"eval_context_length\"] = 5\n",
    "variant[\"warmup_steps\"] = 1000\n",
    "variant[\"learning_rate\"] = 1e-4\n",
    "variant[\"weight_decay\"] = 5e-4\n",
    "variant[\"dataset_num_squence\"] = num_sequences\n",
    "variant[\"dataset_seq_length\"] = seq_data_length\n",
    "variant[\"train_total_epoch\"] = total_epoch\n",
    "variant[\"stocastic_policy\"] = False\n",
    "\n",
    "model = DecisionTransformer02(\n",
    "    state_dim=variant[\"state_dim\"],\n",
    "    state_range= variant[\"state_range\"],\n",
    "    max_length=variant[\"K\"],\n",
    "    eval_context_length=variant[\"eval_context_length\"],\n",
    "    max_ep_len=MAX_EPISODE_LEN,\n",
    "    hidden_size=variant[\"embed_dim\"],\n",
    "    n_layer=variant[\"n_layer\"],\n",
    "    n_head=variant[\"n_head\"],\n",
    "    n_inner=4 * variant[\"embed_dim\"],\n",
    "    activation_function=variant[\"activation_function\"],\n",
    "    n_positions=1024,\n",
    "    resid_pdrop=variant[\"dropout\"],\n",
    "    attn_pdrop=variant[\"dropout\"],\n",
    "    stochastic_policy=variant[\"stocastic_policy\"],\n",
    "    ordering=variant[\"ordering\"],\n",
    "    init_temperature=variant[\"init_temperature\"],\n",
    "    target_entropy=variant[\"target_entropy\"],\n",
    "    #state_mean=self.state_mean,\n",
    "    #state_std=self.state_std,\n",
    ").to(device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step_stochastic_01(self, loss_fn, trajs):\n",
    "    (\n",
    "        states,\n",
    "        rewards,\n",
    "        dones,\n",
    "        rtg,\n",
    "        timesteps,\n",
    "        ordering,\n",
    "        padding_mask,\n",
    "    ) = trajs\n",
    "    \n",
    "\n",
    "    states = states.to(self.device)\n",
    "    rewards = rewards.to(self.device)\n",
    "    dones = dones.to(self.device)\n",
    "    rtg = rtg.to(self.device)\n",
    "    timesteps = timesteps.to(self.device)\n",
    "    ordering = ordering.to(self.device)\n",
    "    padding_mask = padding_mask.to(self.device)\n",
    "    #print(f\"training_input {states[0]}\")\n",
    "    #print(f\"padding_mask:{padding_mask[0]}\")\n",
    "    #print(f\"timesetps:{timesteps[0]}\")\n",
    "    #print(f\"ordering:{ordering[0]}\")\n",
    "    state_target = torch.clone(states)\n",
    "\n",
    "    states_preds = self.model.forward(\n",
    "        states,\n",
    "        timesteps,\n",
    "        ordering,\n",
    "        padding_mask=padding_mask,\n",
    "    )\n",
    "\n",
    "    loss, nll, entropy = loss_fn(\n",
    "        states_preds,  # a_hat_dist\n",
    "        state_target,\n",
    "        padding_mask,\n",
    "        self.model.temperature().detach(),  # no gradient taken here\n",
    "    )\n",
    "    #print(f\"state_target : {state_target[0]}\")\n",
    "    #print(f\"state_preds : {states_preds.mean[0]}\")\n",
    "    self.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "    self.optimizer.step()\n",
    "\n",
    "    self.log_temperature_optimizer.zero_grad()\n",
    "    temperature_loss = (\n",
    "        self.model.temperature() * (entropy - self.model.target_entropy).detach()\n",
    "    )\n",
    "    temperature_loss.backward()\n",
    "    self.log_temperature_optimizer.step()\n",
    "\n",
    "    if self.scheduler is not None:\n",
    "        self.scheduler.step()\n",
    "\n",
    "    return (\n",
    "        loss.detach().cpu().item(),\n",
    "        nll.detach().cpu().item(),\n",
    "        entropy.detach().cpu().item(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjesnk\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/research/online-dt/wandb/run-20240110_120350-qgv0hwom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jesnk/GPT_exp/runs/qgv0hwom' target=\"_blank\">DT02_DET_2024-01-10 21:03:50</a></strong> to <a href='https://wandb.ai/jesnk/GPT_exp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jesnk/GPT_exp' target=\"_blank\">https://wandb.ai/jesnk/GPT_exp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jesnk/GPT_exp/runs/qgv0hwom' target=\"_blank\">https://wandb.ai/jesnk/GPT_exp/runs/qgv0hwom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from lamb import Lamb\n",
    "import wandb\n",
    "from jesnk_utils.utils import get_current_time\n",
    "import asyncio\n",
    "from jesnk_utils.telebot import Telebot\n",
    "\n",
    "telebot = Telebot()\n",
    "\n",
    "# 데이터 로더 설정\n",
    "batch_size = 1024\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "def loss_fn_stocastic(\n",
    "    s_hat_dist,\n",
    "    s,\n",
    "    attention_mask,\n",
    "    entropy_reg,\n",
    "):\n",
    "    # a_hat is a SquashedNormal Distribution\n",
    "    log_likelihood = s_hat_dist.log_likelihood(s)[attention_mask > 0].mean()\n",
    "\n",
    "    entropy = s_hat_dist.entropy().mean()\n",
    "    loss = -(log_likelihood + entropy_reg * entropy)\n",
    "\n",
    "    return (\n",
    "        loss,\n",
    "        -log_likelihood,\n",
    "        entropy,\n",
    "    )\n",
    "    \n",
    "def loss_fn_deterministic(\n",
    "    s_hat,\n",
    "    s,\n",
    "    attention_mask\n",
    "):\n",
    "    # MSE LOSS with attention_mask > 0\n",
    "    s_hat = s_hat\n",
    "    s = s\n",
    "    #print(s_hat.shape, s.shape)\n",
    "    loss = torch.mean((s_hat - s)**2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "optimizer = Lamb(\n",
    "            model.parameters(),\n",
    "            lr=variant[\"learning_rate\"],\n",
    "            weight_decay=variant[\"weight_decay\"],\n",
    "            eps=1e-8,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer, lambda steps: min((steps + 1) / variant[\"warmup_steps\"], 1)\n",
    ")\n",
    "\n",
    "\n",
    "# 학습 루프\n",
    "def train(model, train_loader, loss_fn, optimizer, scheduler, epochs=10, log_dir='./0_gpt_trained_model/'):\n",
    "    model.train()\n",
    "    timestamp = get_current_time()\n",
    "    embed_dim = variant[\"embed_dim\"]\n",
    "    num_heads = variant[\"n_head\"]\n",
    "    num_layers = variant[\"n_layer\"]\n",
    "    seq_data_length = variant[\"dataset_seq_length\"]\n",
    "    num_sequences = variant[\"dataset_num_squence\"]\n",
    "    lr = variant[\"learning_rate\"]\n",
    "    gamma = variant[\"weight_decay\"]\n",
    "    total_epoch = variant[\"train_total_epoch\"]\n",
    "    stocastic_policy = variant[\"stocastic_policy\"]\n",
    "    \n",
    "    if stocastic_policy:\n",
    "        log_temperature_optimizer = torch.optim.Adam(\n",
    "            [model.log_temperature],\n",
    "            lr=1e-4,\n",
    "            betas=[0.9, 0.999],\n",
    "        )\n",
    "    \n",
    "    model_name = f\"{timestamp}_DT_ed{embed_dim}_nh{num_heads}_nl{num_layers}_sdl{seq_data_length}_ns{num_sequences}_lr{lr}_g{gamma}_epoch{total_epoch}\"\n",
    "    log_dir = log_dir + f\"{model_name}/\"\n",
    "    \n",
    "    if telebot_enable:\n",
    "        telebot.send_message(f\"{get_current_time()} : start training {model_name}\")\n",
    "\n",
    "    try:\n",
    "        os.mkdir(log_dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    import os\n",
    "    try:\n",
    "        os.mkdir(log_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        total_token_error = []\n",
    "        epoch_start_time = time.time()\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs.unsqueeze(-1))\n",
    "            \n",
    "            padding_mask = torch.ones((inputs.shape[0], seq_length), dtype=torch.long)\n",
    "            \n",
    "            if stocastic_policy:\n",
    "                loss, nll, entropy = loss_fn(outputs, targets.unsqueeze(-1),attention_mask=padding_mask,entropy_reg=model.temperature().detach())\n",
    "            else :\n",
    "                loss = loss_fn(outputs, targets.unsqueeze(-1),attention_mask=padding_mask)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if stocastic_policy:\n",
    "                log_temperature_optimizer.zero_grad()\n",
    "                temperature_loss = (\n",
    "                    model.temperature() * (entropy - model.target_entropy).detach()\n",
    "                )\n",
    "                temperature_loss.backward()\n",
    "                log_temperature_optimizer.step()\n",
    "            if stocastic_policy:\n",
    "                output_sample = outputs.mean\n",
    "            else :\n",
    "                output_sample = outputs\n",
    "            token_error = torch.abs(targets.detach() - output_sample.detach().reshape(targets.shape)).mean()\n",
    "            total_token_error.append(token_error.cpu())\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if wandb.run is not None:\n",
    "                if variant['stocastic_policy'] :\n",
    "                    wandb.log(\n",
    "                        {\n",
    "                            \"loss\": loss.item(),\n",
    "                            \"nll\": nll.item(),\n",
    "                            \"entropy\": entropy.item(),\n",
    "                            \"token_error\": token_error.item(),\n",
    "                            \"temperature\": model.temperature().item(),\n",
    "                        }\n",
    "                    )\n",
    "                else :                        \n",
    "                    wandb.log(\n",
    "                        {\n",
    "                            \"loss\": loss.item(),\n",
    "                            \"token_error\": token_error.item(),\n",
    "                        }\n",
    "                )\n",
    "        scheduler.step()\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_token_error = np.mean(total_token_error)\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        \n",
    "        if wandb.run is not None:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"avg_loss\": avg_loss,\n",
    "                    \"epoch_token_error\": epoch_token_error,\n",
    "                }\n",
    "            )\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.7f}, token error : {epoch_token_error}Time: {epoch_end_time - epoch_start_time:.4f}s\")\n",
    "        if stocastic_policy:\n",
    "            print(f\"entropy : {entropy}, temperature : {model.temperature()}\")\n",
    "        if epoch % 10 == 0:\n",
    "            model_name = f\"gpt2_ed{embed_dim}_nh{num_heads}_nl{num_layers}_sdl{seq_data_length}_ns{num_sequences}_lr{lr}_g{gamma}_epoch{total_epoch}_tte{epoch_token_error}_ep{epoch}.pt\"\n",
    "            model.save(f\"{log_dir}{model_name}\")\n",
    "            if telebot_enable:\n",
    "                telebot.send_message(f\"{get_current_time()} : token error : {epoch_token_error}\")\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total Learning time : {end_time - start_time:.4f}s\")\n",
    "    if telebot_enable:\n",
    "        telebot.send_message(f\"{get_current_time()} : Finished. Total Learning time : {end_time - start_time:.4f}s\")\n",
    "    return epoch_token_error\n",
    "\n",
    "\n",
    "current_time = get_current_time()\n",
    "\n",
    "wandb_enable = True\n",
    "telebot_enable = False\n",
    "if wandb_enable :\n",
    "    wandb.init(project=\"GPT_exp\", entity=\"jesnk\", name=f\"DT02_DET_{current_time}\")\n",
    "    wandb.config.update(variant)\n",
    "    wandb.watch(model)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = loss_fn_stocastic if variant[\"stocastic_policy\"] else loss_fn_deterministic\n",
    "#last_epoch_token_error = train(model, train_loader, loss_fn, optimizer, scheduler, epochs=total_epoch)\n",
    "#last_epoch_token_error = str(round(last_epoch_token_error, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTransformer02(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(1, 512)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_timestep): Embedding(1000, 512)\n",
       "  (embed_state): Linear(in_features=1, out_features=512, bias=True)\n",
       "  (embed_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (predict_state): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load(\"./0_gpt_trained_model/gpt2_ed512_nh4_nl4_sdl5_ns500000_lr0.0001_g0.0005_epoch1000_tte0.003134428057819605_ep390.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs : tensor([0.7730, 0.7830, 0.7930, 0.8030], device='cuda:0')\n",
      "targets : tensor([0.7830, 0.7930, 0.8030, 0.8130], device='cuda:0')\n",
      "outputs : tensor([0.7848, 0.7940, 0.8032, 0.8123])\n",
      "====================\n",
      "inputs : tensor([0.6093, 0.6193, 0.6293, 0.6393], device='cuda:0')\n",
      "targets : tensor([0.6193, 0.6293, 0.6393, 0.6493], device='cuda:0')\n",
      "outputs : tensor([0.6132, 0.6221, 0.6309, 0.6397])\n",
      "====================\n",
      "inputs : tensor([-0.2970, -0.2870, -0.2770, -0.2670], device='cuda:0')\n",
      "targets : tensor([-0.2870, -0.2770, -0.2670, -0.2570], device='cuda:0')\n",
      "outputs : tensor([-0.2780, -0.2695, -0.2611, -0.2527])\n",
      "====================\n",
      "inputs : tensor([0.2382, 0.2482, 0.2582, 0.2682], device='cuda:0')\n",
      "targets : tensor([0.2482, 0.2582, 0.2682, 0.2782], device='cuda:0')\n",
      "outputs : tensor([0.2410, 0.2496, 0.2581, 0.2665])\n",
      "====================\n",
      "inputs : tensor([0.3437, 0.3537, 0.3637, 0.3737], device='cuda:0')\n",
      "targets : tensor([0.3537, 0.3637, 0.3737, 0.3837], device='cuda:0')\n",
      "outputs : tensor([0.3453, 0.3540, 0.3625, 0.3709])\n",
      "====================\n",
      "inputs : tensor([-0.0677, -0.0577, -0.0477, -0.0377], device='cuda:0')\n",
      "targets : tensor([-0.0577, -0.0477, -0.0377, -0.0277], device='cuda:0')\n",
      "outputs : tensor([-0.0548, -0.0463, -0.0379, -0.0296])\n",
      "====================\n",
      "inputs : tensor([-0.2366, -0.2266, -0.2166, -0.2066], device='cuda:0')\n",
      "targets : tensor([-0.2266, -0.2166, -0.2066, -0.1966], device='cuda:0')\n",
      "outputs : tensor([-0.2188, -0.2103, -0.2019, -0.1935])\n",
      "====================\n",
      "inputs : tensor([0.2815, 0.2915, 0.3015, 0.3115], device='cuda:0')\n",
      "targets : tensor([0.2915, 0.3015, 0.3115, 0.3215], device='cuda:0')\n",
      "outputs : tensor([0.2837, 0.2923, 0.3008, 0.3092])\n",
      "====================\n",
      "inputs : tensor([-0.2278, -0.2178, -0.2078, -0.1978], device='cuda:0')\n",
      "targets : tensor([-0.2178, -0.2078, -0.1978, -0.1878], device='cuda:0')\n",
      "outputs : tensor([-0.2102, -0.2017, -0.1933, -0.1849])\n",
      "====================\n",
      "inputs : tensor([0.8058, 0.8158, 0.8258, 0.8358], device='cuda:0')\n",
      "targets : tensor([0.8158, 0.8258, 0.8358, 0.8458], device='cuda:0')\n",
      "outputs : tensor([0.8204, 0.8297, 0.8389, 0.8480])\n",
      "====================\n",
      "inputs : tensor([-0.1506, -0.1406, -0.1306, -0.1206], device='cuda:0')\n",
      "targets : tensor([-0.1406, -0.1306, -0.1206, -0.1106], device='cuda:0')\n",
      "outputs : tensor([-0.1350, -0.1265, -0.1181, -0.1097])\n",
      "====================\n",
      "inputs : tensor([-0.2425, -0.2325, -0.2225, -0.2125], device='cuda:0')\n",
      "targets : tensor([-0.2325, -0.2225, -0.2125, -0.2025], device='cuda:0')\n",
      "outputs : tensor([-0.2246, -0.2161, -0.2076, -0.1993])\n",
      "====================\n",
      "inputs : tensor([-0.0961, -0.0861, -0.0761, -0.0661], device='cuda:0')\n",
      "targets : tensor([-0.0861, -0.0761, -0.0661, -0.0561], device='cuda:0')\n",
      "outputs : tensor([-0.0822, -0.0737, -0.0653, -0.0570])\n",
      "====================\n",
      "inputs : tensor([0.2803, 0.2903, 0.3003, 0.3103], device='cuda:0')\n",
      "targets : tensor([0.2903, 0.3003, 0.3103, 0.3203], device='cuda:0')\n",
      "outputs : tensor([0.2824, 0.2911, 0.2996, 0.3080])\n",
      "====================\n",
      "inputs : tensor([-0.2373, -0.2273, -0.2173, -0.2073], device='cuda:0')\n",
      "targets : tensor([-0.2273, -0.2173, -0.2073, -0.1973], device='cuda:0')\n",
      "outputs : tensor([-0.2195, -0.2110, -0.2026, -0.1943])\n",
      "====================\n",
      "inputs : tensor([-0.9339, -0.9239, -0.9139, -0.9039], device='cuda:0')\n",
      "targets : tensor([-0.9239, -0.9139, -0.9039, -0.8939], device='cuda:0')\n",
      "outputs : tensor([-0.9427, -0.9332, -0.9236, -0.9142])\n",
      "====================\n",
      "inputs : tensor([0.2607, 0.2707, 0.2807, 0.2907], device='cuda:0')\n",
      "targets : tensor([0.2707, 0.2807, 0.2907, 0.3007], device='cuda:0')\n",
      "outputs : tensor([0.2631, 0.2718, 0.2803, 0.2887])\n",
      "====================\n",
      "inputs : tensor([0.7575, 0.7675, 0.7775, 0.7875], device='cuda:0')\n",
      "targets : tensor([0.7675, 0.7775, 0.7875, 0.7975], device='cuda:0')\n",
      "outputs : tensor([0.7682, 0.7774, 0.7865, 0.7956])\n",
      "====================\n",
      "inputs : tensor([-0.9076, -0.8976, -0.8876, -0.8776], device='cuda:0')\n",
      "targets : tensor([-0.8976, -0.8876, -0.8776, -0.8676], device='cuda:0')\n",
      "outputs : tensor([-0.9113, -0.9020, -0.8927, -0.8835])\n",
      "====================\n",
      "inputs : tensor([0.3507, 0.3607, 0.3707, 0.3807], device='cuda:0')\n",
      "targets : tensor([0.3607, 0.3707, 0.3807, 0.3907], device='cuda:0')\n",
      "outputs : tensor([0.3522, 0.3609, 0.3694, 0.3778])\n",
      "====================\n",
      "inputs : tensor([0.9394, 0.9494, 0.9594, 0.9694], device='cuda:0')\n",
      "targets : tensor([0.9494, 0.9594, 0.9694, 0.9794], device='cuda:0')\n",
      "outputs : tensor([0.9691, 0.9760, 0.9817, 0.9863])\n",
      "====================\n",
      "inputs : tensor([0.7704, 0.7804, 0.7904, 0.8004], device='cuda:0')\n",
      "targets : tensor([0.7804, 0.7904, 0.8004, 0.8104], device='cuda:0')\n",
      "outputs : tensor([0.7820, 0.7912, 0.8004, 0.8095])\n",
      "====================\n",
      "inputs : tensor([-0.0295, -0.0195, -0.0095,  0.0005], device='cuda:0')\n",
      "targets : tensor([-0.0195, -0.0095,  0.0005,  0.0105], device='cuda:0')\n",
      "outputs : tensor([-0.0181, -0.0096, -0.0013,  0.0071])\n",
      "====================\n",
      "inputs : tensor([-0.1562, -0.1462, -0.1362, -0.1262], device='cuda:0')\n",
      "targets : tensor([-0.1462, -0.1362, -0.1262, -0.1162], device='cuda:0')\n",
      "outputs : tensor([-0.1405, -0.1319, -0.1235, -0.1152])\n",
      "====================\n",
      "inputs : tensor([0.5905, 0.6005, 0.6105, 0.6205], device='cuda:0')\n",
      "targets : tensor([0.6005, 0.6105, 0.6205, 0.6305], device='cuda:0')\n",
      "outputs : tensor([0.5939, 0.6027, 0.6115, 0.6202])\n",
      "====================\n",
      "inputs : tensor([-0.4081, -0.3981, -0.3881, -0.3781], device='cuda:0')\n",
      "targets : tensor([-0.3981, -0.3881, -0.3781, -0.3681], device='cuda:0')\n",
      "outputs : tensor([-0.3872, -0.3787, -0.3703, -0.3620])\n",
      "====================\n",
      "inputs : tensor([-0.0774, -0.0674, -0.0574, -0.0474], device='cuda:0')\n",
      "targets : tensor([-0.0674, -0.0574, -0.0474, -0.0374], device='cuda:0')\n",
      "outputs : tensor([-0.0642, -0.0557, -0.0473, -0.0390])\n",
      "====================\n",
      "inputs : tensor([-0.9031, -0.8931, -0.8831, -0.8731], device='cuda:0')\n",
      "targets : tensor([-0.8931, -0.8831, -0.8731, -0.8631], device='cuda:0')\n",
      "outputs : tensor([-0.9061, -0.8968, -0.8876, -0.8784])\n",
      "====================\n",
      "inputs : tensor([-0.5405, -0.5305, -0.5205, -0.5105], device='cuda:0')\n",
      "targets : tensor([-0.5305, -0.5205, -0.5105, -0.5005], device='cuda:0')\n",
      "outputs : tensor([-0.5186, -0.5100, -0.5016, -0.4932])\n",
      "====================\n",
      "inputs : tensor([-0.7003, -0.6903, -0.6803, -0.6703], device='cuda:0')\n",
      "targets : tensor([-0.6903, -0.6803, -0.6703, -0.6603], device='cuda:0')\n",
      "outputs : tensor([-0.6823, -0.6733, -0.6645, -0.6557])\n",
      "====================\n",
      "inputs : tensor([-0.2141, -0.2041, -0.1941, -0.1841], device='cuda:0')\n",
      "targets : tensor([-0.2041, -0.1941, -0.1841, -0.1741], device='cuda:0')\n",
      "outputs : tensor([-0.1968, -0.1883, -0.1798, -0.1715])\n",
      "====================\n",
      "inputs : tensor([-0.7673, -0.7573, -0.7473, -0.7373], device='cuda:0')\n",
      "targets : tensor([-0.7573, -0.7473, -0.7373, -0.7273], device='cuda:0')\n",
      "outputs : tensor([-0.7538, -0.7446, -0.7355, -0.7265])\n",
      "====================\n",
      "inputs : tensor([-0.3924, -0.3824, -0.3724, -0.3624], device='cuda:0')\n",
      "targets : tensor([-0.3824, -0.3724, -0.3624, -0.3524], device='cuda:0')\n",
      "outputs : tensor([-0.3718, -0.3633, -0.3549, -0.3466])\n",
      "====================\n",
      "inputs : tensor([0.9184, 0.9284, 0.9384, 0.9484], device='cuda:0')\n",
      "targets : tensor([0.9284, 0.9384, 0.9484, 0.9584], device='cuda:0')\n",
      "outputs : tensor([0.9465, 0.9554, 0.9636, 0.9710])\n",
      "====================\n",
      "inputs : tensor([-0.0534, -0.0434, -0.0334, -0.0234], device='cuda:0')\n",
      "targets : tensor([-0.0434, -0.0334, -0.0234, -0.0134], device='cuda:0')\n",
      "outputs : tensor([-0.0411, -0.0326, -0.0242, -0.0159])\n",
      "====================\n",
      "inputs : tensor([0.6599, 0.6699, 0.6799, 0.6899], device='cuda:0')\n",
      "targets : tensor([0.6699, 0.6799, 0.6899, 0.6999], device='cuda:0')\n",
      "outputs : tensor([0.6655, 0.6745, 0.6834, 0.6923])\n",
      "====================\n",
      "inputs : tensor([-0.3973, -0.3873, -0.3773, -0.3673], device='cuda:0')\n",
      "targets : tensor([-0.3873, -0.3773, -0.3673, -0.3573], device='cuda:0')\n",
      "outputs : tensor([-0.3766, -0.3681, -0.3597, -0.3514])\n",
      "====================\n",
      "inputs : tensor([-0.4759, -0.4659, -0.4559, -0.4459], device='cuda:0')\n",
      "targets : tensor([-0.4659, -0.4559, -0.4459, -0.4359], device='cuda:0')\n",
      "outputs : tensor([-0.4543, -0.4458, -0.4374, -0.4291])\n",
      "====================\n",
      "inputs : tensor([-0.0408, -0.0308, -0.0208, -0.0108], device='cuda:0')\n",
      "targets : tensor([-0.0308, -0.0208, -0.0108, -0.0008], device='cuda:0')\n",
      "outputs : tensor([-0.0290, -0.0205, -0.0121, -0.0038])\n",
      "====================\n",
      "inputs : tensor([0.9098, 0.9198, 0.9298, 0.9398], device='cuda:0')\n",
      "targets : tensor([0.9198, 0.9298, 0.9398, 0.9498], device='cuda:0')\n",
      "outputs : tensor([0.9365, 0.9457, 0.9545, 0.9626])\n",
      "====================\n",
      "inputs : tensor([0.4299, 0.4399, 0.4499, 0.4599], device='cuda:0')\n",
      "targets : tensor([0.4399, 0.4499, 0.4599, 0.4699], device='cuda:0')\n",
      "outputs : tensor([0.4312, 0.4398, 0.4484, 0.4569])\n",
      "====================\n",
      "inputs : tensor([0.6537, 0.6637, 0.6737, 0.6837], device='cuda:0')\n",
      "targets : tensor([0.6637, 0.6737, 0.6837, 0.6937], device='cuda:0')\n",
      "outputs : tensor([0.6591, 0.6681, 0.6770, 0.6859])\n",
      "====================\n",
      "inputs : tensor([-0.3674, -0.3574, -0.3474, -0.3374], device='cuda:0')\n",
      "targets : tensor([-0.3574, -0.3474, -0.3374, -0.3274], device='cuda:0')\n",
      "outputs : tensor([-0.3472, -0.3387, -0.3303, -0.3220])\n",
      "====================\n",
      "inputs : tensor([-0.6487, -0.6387, -0.6287, -0.6187], device='cuda:0')\n",
      "targets : tensor([-0.6387, -0.6287, -0.6187, -0.6087], device='cuda:0')\n",
      "outputs : tensor([-0.6285, -0.6197, -0.6110, -0.6024])\n",
      "====================\n",
      "inputs : tensor([-0.1145, -0.1045, -0.0945, -0.0845], device='cuda:0')\n",
      "targets : tensor([-0.1045, -0.0945, -0.0845, -0.0745], device='cuda:0')\n",
      "outputs : tensor([-0.1001, -0.0916, -0.0831, -0.0748])\n",
      "====================\n",
      "inputs : tensor([-0.5384, -0.5284, -0.5184, -0.5084], device='cuda:0')\n",
      "targets : tensor([-0.5284, -0.5184, -0.5084, -0.4984], device='cuda:0')\n",
      "outputs : tensor([-0.5166, -0.5080, -0.4996, -0.4912])\n",
      "====================\n",
      "inputs : tensor([-0.1865, -0.1765, -0.1665, -0.1565], device='cuda:0')\n",
      "targets : tensor([-0.1765, -0.1665, -0.1565, -0.1465], device='cuda:0')\n",
      "outputs : tensor([-0.1699, -0.1614, -0.1530, -0.1446])\n",
      "====================\n",
      "inputs : tensor([0.5758, 0.5858, 0.5958, 0.6058], device='cuda:0')\n",
      "targets : tensor([0.5858, 0.5958, 0.6058, 0.6158], device='cuda:0')\n",
      "outputs : tensor([0.5788, 0.5877, 0.5964, 0.6052])\n",
      "====================\n",
      "inputs : tensor([0.3507, 0.3607, 0.3707, 0.3807], device='cuda:0')\n",
      "targets : tensor([0.3607, 0.3707, 0.3807, 0.3907], device='cuda:0')\n",
      "outputs : tensor([0.3522, 0.3609, 0.3694, 0.3778])\n",
      "====================\n",
      "inputs : tensor([0.1313, 0.1413, 0.1513, 0.1613], device='cuda:0')\n",
      "targets : tensor([0.1413, 0.1513, 0.1613, 0.1713], device='cuda:0')\n",
      "outputs : tensor([0.1370, 0.1455, 0.1540, 0.1623])\n",
      "====================\n",
      "inputs : tensor([-0.4499, -0.4399, -0.4299, -0.4199], device='cuda:0')\n",
      "targets : tensor([-0.4399, -0.4299, -0.4199, -0.4099], device='cuda:0')\n",
      "outputs : tensor([-0.4285, -0.4200, -0.4116, -0.4033])\n",
      "====================\n",
      "inputs : tensor([-0.0568, -0.0468, -0.0368, -0.0268], device='cuda:0')\n",
      "targets : tensor([-0.0468, -0.0368, -0.0268, -0.0168], device='cuda:0')\n",
      "outputs : tensor([-0.0443, -0.0358, -0.0275, -0.0192])\n",
      "====================\n",
      "inputs : tensor([-0.9671, -0.9571, -0.9471, -0.9371], device='cuda:0')\n",
      "targets : tensor([-0.9571, -0.9471, -0.9371, -0.9271], device='cuda:0')\n",
      "outputs : tensor([-0.9771, -0.9706, -0.9630, -0.9545])\n",
      "====================\n",
      "inputs : tensor([-0.7830, -0.7730, -0.7630, -0.7530], device='cuda:0')\n",
      "targets : tensor([-0.7730, -0.7630, -0.7530, -0.7430], device='cuda:0')\n",
      "outputs : tensor([-0.7709, -0.7617, -0.7525, -0.7434])\n",
      "====================\n",
      "inputs : tensor([-0.4251, -0.4151, -0.4051, -0.3951], device='cuda:0')\n",
      "targets : tensor([-0.4151, -0.4051, -0.3951, -0.3851], device='cuda:0')\n",
      "outputs : tensor([-0.4040, -0.3955, -0.3871, -0.3788])\n",
      "====================\n",
      "inputs : tensor([-0.5258, -0.5158, -0.5058, -0.4958], device='cuda:0')\n",
      "targets : tensor([-0.5158, -0.5058, -0.4958, -0.4858], device='cuda:0')\n",
      "outputs : tensor([-0.5040, -0.4954, -0.4870, -0.4786])\n",
      "====================\n",
      "inputs : tensor([0.4995, 0.5095, 0.5195, 0.5295], device='cuda:0')\n",
      "targets : tensor([0.5095, 0.5195, 0.5295, 0.5395], device='cuda:0')\n",
      "outputs : tensor([0.5012, 0.5099, 0.5186, 0.5272])\n",
      "====================\n",
      "inputs : tensor([0.3185, 0.3285, 0.3385, 0.3485], device='cuda:0')\n",
      "targets : tensor([0.3285, 0.3385, 0.3485, 0.3585], device='cuda:0')\n",
      "outputs : tensor([0.3203, 0.3289, 0.3374, 0.3459])\n",
      "====================\n",
      "inputs : tensor([-0.8515, -0.8415, -0.8315, -0.8215], device='cuda:0')\n",
      "targets : tensor([-0.8415, -0.8315, -0.8215, -0.8115], device='cuda:0')\n",
      "outputs : tensor([-0.8476, -0.8380, -0.8285, -0.8191])\n",
      "====================\n",
      "inputs : tensor([-0.5695, -0.5595, -0.5495, -0.5395], device='cuda:0')\n",
      "targets : tensor([-0.5595, -0.5495, -0.5395, -0.5295], device='cuda:0')\n",
      "outputs : tensor([-0.5477, -0.5391, -0.5306, -0.5222])\n",
      "====================\n",
      "inputs : tensor([-0.9137, -0.9037, -0.8937, -0.8837], device='cuda:0')\n",
      "targets : tensor([-0.9037, -0.8937, -0.8837, -0.8737], device='cuda:0')\n",
      "outputs : tensor([-0.9185, -0.9091, -0.8998, -0.8906])\n",
      "====================\n",
      "inputs : tensor([-0.8768, -0.8668, -0.8568, -0.8468], device='cuda:0')\n",
      "targets : tensor([-0.8668, -0.8568, -0.8468, -0.8368], device='cuda:0')\n",
      "outputs : tensor([-0.8764, -0.8671, -0.8577, -0.8482])\n",
      "====================\n",
      "inputs : tensor([-0.2811, -0.2711, -0.2611, -0.2511], device='cuda:0')\n",
      "targets : tensor([-0.2711, -0.2611, -0.2511, -0.2411], device='cuda:0')\n",
      "outputs : tensor([-0.2624, -0.2539, -0.2455, -0.2371])\n",
      "====================\n",
      "inputs : tensor([-0.3147, -0.3047, -0.2947, -0.2847], device='cuda:0')\n",
      "targets : tensor([-0.3047, -0.2947, -0.2847, -0.2747], device='cuda:0')\n",
      "outputs : tensor([-0.2954, -0.2869, -0.2785, -0.2701])\n",
      "====================\n",
      "inputs : tensor([-0.7875, -0.7775, -0.7675, -0.7575], device='cuda:0')\n",
      "targets : tensor([-0.7775, -0.7675, -0.7575, -0.7475], device='cuda:0')\n",
      "outputs : tensor([-0.7759, -0.7666, -0.7574, -0.7483])\n",
      "====================\n",
      "inputs : tensor([0.8046, 0.8146, 0.8246, 0.8346], device='cuda:0')\n",
      "targets : tensor([0.8146, 0.8246, 0.8346, 0.8446], device='cuda:0')\n",
      "outputs : tensor([0.8191, 0.8284, 0.8376, 0.8467])\n",
      "====================\n",
      "inputs : tensor([0.0548, 0.0648, 0.0748, 0.0848], device='cuda:0')\n",
      "targets : tensor([0.0648, 0.0748, 0.0848, 0.0948], device='cuda:0')\n",
      "outputs : tensor([0.0630, 0.0715, 0.0800, 0.0883])\n",
      "====================\n",
      "inputs : tensor([0.6681, 0.6781, 0.6881, 0.6981], device='cuda:0')\n",
      "targets : tensor([0.6781, 0.6881, 0.6981, 0.7081], device='cuda:0')\n",
      "outputs : tensor([0.6741, 0.6831, 0.6920, 0.7009])\n",
      "====================\n",
      "inputs : tensor([-0.8678, -0.8578, -0.8478, -0.8378], device='cuda:0')\n",
      "targets : tensor([-0.8578, -0.8478, -0.8378, -0.8278], device='cuda:0')\n",
      "outputs : tensor([-0.8662, -0.8568, -0.8473, -0.8378])\n",
      "====================\n",
      "inputs : tensor([0.7469, 0.7569, 0.7669, 0.7769], device='cuda:0')\n",
      "targets : tensor([0.7569, 0.7669, 0.7769, 0.7869], device='cuda:0')\n",
      "outputs : tensor([0.7569, 0.7660, 0.7751, 0.7842])\n",
      "====================\n",
      "inputs : tensor([0.3975, 0.4075, 0.4175, 0.4275], device='cuda:0')\n",
      "targets : tensor([0.4075, 0.4175, 0.4275, 0.4375], device='cuda:0')\n",
      "outputs : tensor([0.3988, 0.4075, 0.4160, 0.4245])\n",
      "====================\n",
      "inputs : tensor([0.4692, 0.4792, 0.4893, 0.4992], device='cuda:0')\n",
      "targets : tensor([0.4792, 0.4893, 0.4992, 0.5092], device='cuda:0')\n",
      "outputs : tensor([0.4707, 0.4794, 0.4880, 0.4966])\n",
      "====================\n",
      "inputs : tensor([-0.0325, -0.0225, -0.0125, -0.0025], device='cuda:0')\n",
      "targets : tensor([-0.0225, -0.0125, -0.0025,  0.0075], device='cuda:0')\n",
      "outputs : tensor([-0.0211, -0.0126, -0.0042,  0.0041])\n",
      "====================\n",
      "inputs : tensor([0.1633, 0.1733, 0.1833, 0.1933], device='cuda:0')\n",
      "targets : tensor([0.1733, 0.1833, 0.1933, 0.2033], device='cuda:0')\n",
      "outputs : tensor([0.1681, 0.1766, 0.1850, 0.1934])\n",
      "====================\n",
      "inputs : tensor([0.7788, 0.7888, 0.7988, 0.8088], device='cuda:0')\n",
      "targets : tensor([0.7888, 0.7988, 0.8088, 0.8188], device='cuda:0')\n",
      "outputs : tensor([0.7910, 0.8002, 0.8094, 0.8185])\n",
      "====================\n",
      "inputs : tensor([0.0617, 0.0717, 0.0817, 0.0917], device='cuda:0')\n",
      "targets : tensor([0.0717, 0.0817, 0.0917, 0.1017], device='cuda:0')\n",
      "outputs : tensor([0.0697, 0.0782, 0.0867, 0.0950])\n",
      "====================\n",
      "inputs : tensor([-0.8129, -0.8029, -0.7929, -0.7829], device='cuda:0')\n",
      "targets : tensor([-0.8029, -0.7929, -0.7829, -0.7729], device='cuda:0')\n",
      "outputs : tensor([-0.8039, -0.7945, -0.7852, -0.7760])\n",
      "====================\n",
      "inputs : tensor([0.0543, 0.0643, 0.0743, 0.0843], device='cuda:0')\n",
      "targets : tensor([0.0643, 0.0743, 0.0843, 0.0943], device='cuda:0')\n",
      "outputs : tensor([0.0625, 0.0711, 0.0795, 0.0879])\n",
      "====================\n",
      "inputs : tensor([0.7520, 0.7620, 0.7720, 0.7820], device='cuda:0')\n",
      "targets : tensor([0.7620, 0.7720, 0.7820, 0.7920], device='cuda:0')\n",
      "outputs : tensor([0.7623, 0.7714, 0.7805, 0.7896])\n",
      "====================\n",
      "inputs : tensor([-0.1203, -0.1103, -0.1003, -0.0903], device='cuda:0')\n",
      "targets : tensor([-0.1103, -0.1003, -0.0903, -0.0803], device='cuda:0')\n",
      "outputs : tensor([-0.1057, -0.0971, -0.0887, -0.0804])\n",
      "====================\n",
      "inputs : tensor([-0.9758, -0.9658, -0.9558, -0.9458], device='cuda:0')\n",
      "targets : tensor([-0.9658, -0.9558, -0.9458, -0.9358], device='cuda:0')\n",
      "outputs : tensor([-0.9832, -0.9779, -0.9715, -0.9641])\n",
      "====================\n",
      "inputs : tensor([0.6009, 0.6109, 0.6209, 0.6309], device='cuda:0')\n",
      "targets : tensor([0.6109, 0.6209, 0.6309, 0.6409], device='cuda:0')\n",
      "outputs : tensor([0.6045, 0.6134, 0.6222, 0.6309])\n",
      "====================\n",
      "inputs : tensor([0.3147, 0.3247, 0.3347, 0.3447], device='cuda:0')\n",
      "targets : tensor([0.3247, 0.3347, 0.3447, 0.3547], device='cuda:0')\n",
      "outputs : tensor([0.3165, 0.3251, 0.3336, 0.3421])\n",
      "====================\n",
      "inputs : tensor([0.7055, 0.7155, 0.7255, 0.7355], device='cuda:0')\n",
      "targets : tensor([0.7155, 0.7255, 0.7355, 0.7455], device='cuda:0')\n",
      "outputs : tensor([0.7131, 0.7222, 0.7312, 0.7401])\n",
      "====================\n",
      "inputs : tensor([0.4745, 0.4845, 0.4945, 0.5045], device='cuda:0')\n",
      "targets : tensor([0.4845, 0.4945, 0.5045, 0.5145], device='cuda:0')\n",
      "outputs : tensor([0.4760, 0.4847, 0.4933, 0.5019])\n",
      "====================\n",
      "inputs : tensor([0.5253, 0.5353, 0.5453, 0.5553], device='cuda:0')\n",
      "targets : tensor([0.5353, 0.5453, 0.5553, 0.5653], device='cuda:0')\n",
      "outputs : tensor([0.5273, 0.5361, 0.5448, 0.5534])\n",
      "====================\n",
      "inputs : tensor([0.3053, 0.3153, 0.3253, 0.3353], device='cuda:0')\n",
      "targets : tensor([0.3153, 0.3253, 0.3353, 0.3453], device='cuda:0')\n",
      "outputs : tensor([0.3072, 0.3159, 0.3244, 0.3328])\n",
      "====================\n",
      "inputs : tensor([-0.6323, -0.6223, -0.6123, -0.6023], device='cuda:0')\n",
      "targets : tensor([-0.6223, -0.6123, -0.6023, -0.5923], device='cuda:0')\n",
      "outputs : tensor([-0.6116, -0.6029, -0.5942, -0.5857])\n",
      "====================\n",
      "inputs : tensor([0.6587, 0.6687, 0.6787, 0.6887], device='cuda:0')\n",
      "targets : tensor([0.6687, 0.6787, 0.6887, 0.6987], device='cuda:0')\n",
      "outputs : tensor([0.6643, 0.6733, 0.6822, 0.6911])\n",
      "====================\n",
      "inputs : tensor([-0.3397, -0.3297, -0.3197, -0.3097], device='cuda:0')\n",
      "targets : tensor([-0.3297, -0.3197, -0.3097, -0.2997], device='cuda:0')\n",
      "outputs : tensor([-0.3199, -0.3114, -0.3030, -0.2947])\n",
      "====================\n",
      "inputs : tensor([-0.5858, -0.5758, -0.5658, -0.5558], device='cuda:0')\n",
      "targets : tensor([-0.5758, -0.5658, -0.5558, -0.5458], device='cuda:0')\n",
      "outputs : tensor([-0.5642, -0.5556, -0.5471, -0.5386])\n",
      "====================\n",
      "inputs : tensor([-0.3984, -0.3884, -0.3784, -0.3684], device='cuda:0')\n",
      "targets : tensor([-0.3884, -0.3784, -0.3684, -0.3584], device='cuda:0')\n",
      "outputs : tensor([-0.3777, -0.3692, -0.3608, -0.3525])\n",
      "====================\n",
      "inputs : tensor([-0.5990, -0.5890, -0.5790, -0.5690], device='cuda:0')\n",
      "targets : tensor([-0.5890, -0.5790, -0.5690, -0.5590], device='cuda:0')\n",
      "outputs : tensor([-0.5776, -0.5689, -0.5603, -0.5519])\n",
      "====================\n",
      "inputs : tensor([-0.5501, -0.5401, -0.5301, -0.5201], device='cuda:0')\n",
      "targets : tensor([-0.5401, -0.5301, -0.5201, -0.5101], device='cuda:0')\n",
      "outputs : tensor([-0.5282, -0.5196, -0.5112, -0.5028])\n",
      "====================\n",
      "inputs : tensor([-0.8277, -0.8177, -0.8077, -0.7977], device='cuda:0')\n",
      "targets : tensor([-0.8177, -0.8077, -0.7977, -0.7877], device='cuda:0')\n",
      "outputs : tensor([-0.8206, -0.8111, -0.8017, -0.7924])\n",
      "====================\n",
      "inputs : tensor([-0.2067, -0.1967, -0.1867, -0.1767], device='cuda:0')\n",
      "targets : tensor([-0.1967, -0.1867, -0.1767, -0.1667], device='cuda:0')\n",
      "outputs : tensor([-0.1896, -0.1811, -0.1727, -0.1643])\n",
      "====================\n",
      "inputs : tensor([-0.7041, -0.6941, -0.6841, -0.6741], device='cuda:0')\n",
      "targets : tensor([-0.6941, -0.6841, -0.6741, -0.6641], device='cuda:0')\n",
      "outputs : tensor([-0.6863, -0.6773, -0.6684, -0.6596])\n",
      "====================\n",
      "inputs : tensor([-0.0154, -0.0054,  0.0046,  0.0146], device='cuda:0')\n",
      "targets : tensor([-0.0054,  0.0046,  0.0146,  0.0246], device='cuda:0')\n",
      "outputs : tensor([-0.0046,  0.0039,  0.0123,  0.0206])\n",
      "====================\n",
      "inputs : tensor([-0.6704, -0.6604, -0.6504, -0.6404], device='cuda:0')\n",
      "targets : tensor([-0.6604, -0.6504, -0.6404, -0.6304], device='cuda:0')\n",
      "outputs : tensor([-0.6509, -0.6420, -0.6333, -0.6246])\n",
      "====================\n",
      "inputs : tensor([-0.2404, -0.2304, -0.2204, -0.2104], device='cuda:0')\n",
      "targets : tensor([-0.2304, -0.2204, -0.2104, -0.2004], device='cuda:0')\n",
      "outputs : tensor([-0.2225, -0.2139, -0.2055, -0.1972])\n",
      "====================\n",
      "Test Loss: 0.0001\n",
      "Test Token Error: 0.0077\n",
      "count : 100\n"
     ]
    }
   ],
   "source": [
    "def test(model, test_loader, stochastic_policy=False):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_token_error = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            #print(inputs.shape, targets.shape)\n",
    "            outputs = model(inputs.unsqueeze(-1))\n",
    "            padding_mask = torch.ones((inputs.shape[0], seq_length), dtype=torch.long)\n",
    "            print(f\"inputs : {inputs[0]}\")\n",
    "            print(f\"targets : {targets[0]}\")\n",
    "            print(f\"outputs : {outputs[0].detach().cpu().squeeze()}\")\n",
    "            if stochastic_policy :\n",
    "                loss, nll, entropy = loss_fn(outputs, targets.unsqueeze(-1),attention_mask=padding_mask,entropy_reg=model.temperature().detach())\n",
    "            else :\n",
    "                loss = loss_fn(outputs, targets.unsqueeze(-1),attention_mask=padding_mask)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if stochastic_policy:\n",
    "                output_sample = outputs.mean\n",
    "            else :\n",
    "                output_sample = outputs\n",
    "            token_error = torch.abs(targets.detach() - output_sample.detach().reshape(targets.shape)).mean()\n",
    "            print(\"=\"*20)\n",
    "\n",
    "            total_token_error.append(token_error.cpu())\n",
    "            count += 1\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_token_error = np.mean(total_token_error)\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Test Token Error: {avg_token_error:.4f}\")\n",
    "    print(f\"count : {count}\")\n",
    "\n",
    "# 테스트 데이터 생성 및 데이터셋 객체 생성\n",
    "test_sequences = create_sequences(seq_length=seq_data_length, num_sequences=100000)  # 예: 200개의 테스트 시퀀스 생성\n",
    "test_dataset = SequenceDataset(test_sequences)\n",
    "\n",
    "# 데이터 로더 설정\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "\n",
    "# 테스트 실행\n",
    "test(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
